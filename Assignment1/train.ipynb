{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a28a0b39",
   "metadata": {},
   "source": [
    "# CNN training notebook (clean split)\n",
    "\n",
    "Run these in order:\n",
    "1. **Config + imports**\n",
    "2. **Dataset helpers**\n",
    "3. **Train** (preload + timing + parameter print)\n",
    "4. **Tune** (optional)\n",
    "5. **Evaluate** (optional)\n",
    "\n",
    "Notes:\n",
    "- Dataset scanning + image decoding are intentionally in this notebook (not `model.py`).\n",
    "- `model.py` is reloaded in Cell 2 so changes to the training loop (like `load_arr`) are picked up without restarting the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e861bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 1) Imports + reload model.py + config\n",
    "# ==========================================================\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import cv2\n",
    "import model as cpp_train\n",
    "\n",
    "# If model.py changed, ensure we use the latest definitions (e.g., train(..., load_arr=...))\n",
    "cpp_train = importlib.reload(cpp_train)\n",
    "\n",
    "# ---------------------------\n",
    "# Config\n",
    "# ---------------------------\n",
    "DATA_ROOT = \"data_2\"\n",
    "EPOCHS = 14\n",
    "BATCH_SIZE = 64\n",
    "VAL_FRAC = 0.2\n",
    "LR = 1e-3\n",
    "SEED = 0\n",
    "\n",
    "# Optional caps\n",
    "MAX_IMAGES = 0  # 0 = no cap\n",
    "\n",
    "# Logging/validation cadence (env-driven inside model.py)\n",
    "LOG_EVERY_SEC = 0        # 0 disables time-based logging\n",
    "LOG_EVERY_BATCHES = 1    # print every N batches (1 = every batch)\n",
    "METRICS_EVERY_BATCHES = 1\n",
    "VAL_EVERY = 1            # validate every N epochs (1 = every epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e5510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 2) Dataset helpers (folder-per-class) + image decode\n",
    "# ==========================================================\n",
    "def _list_class_dirs(root: Path) -> list[Path]:\n",
    "    return sorted([p for p in root.iterdir() if p.is_dir()])\n",
    "\n",
    "\n",
    "def infer_class_mapping(root: Path):\n",
    "    \"\"\"Return (class_names, class_to_idx).\n",
    "    - If all folder names are digits, map by integer value.\n",
    "    - Otherwise map by lexicographic order.\"\"\"\n",
    "    class_dirs = _list_class_dirs(root)\n",
    "    if not class_dirs:\n",
    "        raise FileNotFoundError(f\"no class folders found under: {root}\")\n",
    "\n",
    "    names = [d.name for d in class_dirs]\n",
    "    if all(n.isdigit() for n in names):\n",
    "        idxs = sorted(int(n) for n in names)\n",
    "        max_idx = max(idxs)\n",
    "        class_names = [\"\" for _ in range(max_idx + 1)]\n",
    "        for n in names:\n",
    "            class_names[int(n)] = n\n",
    "        class_to_idx = {name: int(name) for name in names}\n",
    "        return class_names, class_to_idx\n",
    "\n",
    "    class_names = sorted(names)\n",
    "    class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
    "    return class_names, class_to_idx\n",
    "\n",
    "\n",
    "def load_dataset_image_label_pairs(root_dir: str | Path, *, max_images: int = 0):\n",
    "    \"\"\"Return (items, class_names) where items is [(Path, class_idx), ...].\"\"\"\n",
    "    root = Path(root_dir)\n",
    "    if not root.exists():\n",
    "        raise FileNotFoundError(f\"dataset root not found: {root}\")\n",
    "\n",
    "    class_names, class_to_idx = infer_class_mapping(root)\n",
    "    exts = {\".png\", \".jpg\", \".jpeg\", \".bmp\"}\n",
    "    items: list[tuple[Path, int]] = []\n",
    "    for class_dir in _list_class_dirs(root):\n",
    "        label = int(class_to_idx[class_dir.name])\n",
    "        for p in class_dir.iterdir():\n",
    "            if p.is_file() and p.suffix.lower() in exts:\n",
    "                items.append((p, label))\n",
    "                if int(max_images) > 0 and len(items) >= int(max_images):\n",
    "                    return items, class_names\n",
    "\n",
    "    if not items:\n",
    "        raise FileNotFoundError(f\"no images found under: {root}\")\n",
    "    return items, class_names\n",
    "\n",
    "\n",
    "def load_image_rgb_u8_hwc_32x32(image_path: str | Path):\n",
    "    \"\"\"Load image as 32x32 RGB uint8 HWC using OpenCV.\"\"\"\n",
    "    img_bgr = cv2.imread(str(image_path), cv2.IMREAD_COLOR)\n",
    "    if img_bgr is None:\n",
    "        raise FileNotFoundError(f\"failed to read image: {image_path}\")\n",
    "    h, w = img_bgr.shape[:2]\n",
    "    interpolation = cv2.INTER_CUBIC if (h < 32 or w < 32) else cv2.INTER_AREA\n",
    "    resized = cv2.resize(img_bgr, (32, 32), interpolation=interpolation)\n",
    "    rgb = cv2.cvtColor(resized, cv2.COLOR_BGR2RGB)\n",
    "    return rgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7168a5d8",
   "metadata": {},
   "source": [
    "# Model architecture (design + rationale)\n",
    "\n",
    "**Architecture (forward pass):**\n",
    "- Input: 32×32 RGB\n",
    "- 4× Conv(3×3, valid) blocks with BatchNorm + ReLU + Dropout\n",
    "- MaxPool(2×2) after the 2nd and 4th conv blocks\n",
    "- Flatten → Dense(512) → Dense(num_classes)\n",
    "\n",
    "**Why this design fits the assignment:**\n",
    "- 3×3 valid convolutions keep the model small and fast on 32×32 images.\n",
    "- BatchNorm stabilizes training with this custom autograd backend.\n",
    "- Dropout helps regularization and reduces overfitting.\n",
    "- Two pooling stages reduce spatial size before the fully-connected head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# (Optional) Perf sanity: benchmark conv2d / maxpool2d kernels\n",
    "# ==========================================================\n",
    "# This measures the C++ backend performance. If you rebuilt libtensor.dylib\n",
    "# with -O3, you should see improved timings here.\n",
    "\n",
    "import time\n",
    "import importlib\n",
    "\n",
    "import model as cpp_train\n",
    "importlib.reload(cpp_train)\n",
    "\n",
    "from tensor_ctypes import Tensor\n",
    "\n",
    "def _bench(name, fn, iters=50, warmup=10):\n",
    "    for _ in range(warmup):\n",
    "        fn()\n",
    "    t0 = time.perf_counter()\n",
    "    for _ in range(iters):\n",
    "        fn()\n",
    "    t1 = time.perf_counter()\n",
    "    dt = (t1 - t0)\n",
    "    print(f\"{name:24s}  {dt/iters*1e3:8.3f} ms/iter  ({iters} iters)\")\n",
    "\n",
    "# ---------------------------\n",
    "# 1) Isolated conv2d 3x3 valid (hot path in this project)\n",
    "# ---------------------------\n",
    "B = 64\n",
    "x = Tensor.randn((B, 3, 32, 32), requires_grad=False, seed=0)\n",
    "w1 = Tensor.randn((32, 3, 3, 3), requires_grad=False, seed=1)\n",
    "b1 = Tensor.zeros((32,), requires_grad=False)\n",
    "\n",
    "_bench(\"conv2d 3x3 valid\", lambda: x.conv2d(w1, b1, stride=1, padding=0), iters=30, warmup=5)\n",
    "\n",
    "# ---------------------------\n",
    "# 2) MaxPool2d 2x2 stride=2 (hot path)\n",
    "# ---------------------------\n",
    "y = x.conv2d(w1, b1, stride=1, padding=0).relu()  # (B,32,30,30)\n",
    "_bench(\"maxpool2d k2 s2\", lambda: y.maxpool2d(kernel=2, stride=2), iters=80, warmup=10)\n",
    "\n",
    "# ---------------------------\n",
    "# 3) End-to-end CNN forward (no backward)\n",
    "# ---------------------------\n",
    "# Try to reuse NUM_CLASSES if earlier cells ran; otherwise fall back to 10.\n",
    "if \"NUM_CLASSES\" not in globals():\n",
    "    NUM_CLASSES = 10\n",
    "\n",
    "m_bench = cpp_train.CNN(num_classes=int(NUM_CLASSES))\n",
    "x2 = Tensor.randn((B, 3, 32, 32), requires_grad=False, seed=123)\n",
    "_bench(\"CNN forward\", lambda: m_bench.forward_logits(x2, training=False), iters=10, warmup=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c4cfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 3) Model stats: trainable params + MACs/FLOPs per forward\n",
    "# ==========================================================\n",
    "from pathlib import Path\n",
    "\n",
    "# Infer num_classes from folders (does not read images)\n",
    "class_names, _ = infer_class_mapping(Path(DATA_ROOT))\n",
    "NUM_CLASSES = len(class_names)\n",
    "print(f\"num_classes inferred from {DATA_ROOT!r}: {NUM_CLASSES}\")\n",
    "\n",
    "m_stats = cpp_train.CNN(num_classes=NUM_CLASSES)\n",
    "\n",
    "def _numel(shape):\n",
    "    n = 1\n",
    "    for d in shape:\n",
    "        n *= int(d)\n",
    "    return int(n)\n",
    "\n",
    "total_params = 0\n",
    "trainable_params = 0\n",
    "for name, t in m_stats.named_tensors():\n",
    "    n = _numel(t.shape())\n",
    "    total_params += n\n",
    "    if bool(t.has_grad()):\n",
    "        trainable_params += n\n",
    "print(f\"Total parameters:     {total_params}\")\n",
    "print(f\"Trainable parameters: {trainable_params}\")\n",
    "\n",
    "# ---- MACs / FLOPs (conv + linear only; BN/ReLU/Dropout/pool ignored)\n",
    "def conv2d_valid_macs(in_h, in_w, in_c, out_c, k=3):\n",
    "    out_h = in_h - k + 1\n",
    "    out_w = in_w - k + 1\n",
    "    if out_h <= 0 or out_w <= 0:\n",
    "        raise ValueError(\"invalid conv output shape\")\n",
    "    macs = out_h * out_w * out_c * in_c * k * k\n",
    "    return out_h, out_w, macs\n",
    "\n",
    "def linear_macs(in_features, out_features):\n",
    "    return in_features * out_features\n",
    "\n",
    "rows = []\n",
    "h, w, c = 32, 32, 3\n",
    "\n",
    "h, w, mac = conv2d_valid_macs(h, w, c, 32, k=3)\n",
    "rows.append((\"conv1 3x3\", f\"{h}x{w}x32\", mac))\n",
    "c = 32\n",
    "h, w, mac = conv2d_valid_macs(h, w, c, 32, k=3)\n",
    "rows.append((\"conv2 3x3\", f\"{h}x{w}x32\", mac))\n",
    "\n",
    "# pool2\n",
    "h, w = h // 2, w // 2\n",
    "\n",
    "h, w, mac = conv2d_valid_macs(h, w, c, 64, k=3)\n",
    "rows.append((\"conv3 3x3\", f\"{h}x{w}x64\", mac))\n",
    "c = 64\n",
    "h, w, mac = conv2d_valid_macs(h, w, c, 64, k=3)\n",
    "rows.append((\"conv4 3x3\", f\"{h}x{w}x64\", mac))\n",
    "\n",
    "# pool2\n",
    "h, w = h // 2, w // 2\n",
    "flatten = c * h * w  # 64*5*5=1600\n",
    "rows.append((\"flatten\", f\"{flatten}\", 0))\n",
    "\n",
    "mac_fc1 = linear_macs(flatten, 512)\n",
    "rows.append((\"fc1\", \"512\", mac_fc1))\n",
    "mac_fc2 = linear_macs(512, NUM_CLASSES)\n",
    "rows.append((\"fc2\", f\"{NUM_CLASSES}\", mac_fc2))\n",
    "\n",
    "total_macs = sum(r[2] for r in rows)\n",
    "total_flops = 2 * total_macs  # common convention: 1 MAC = 2 FLOPs (mul+add)\n",
    "\n",
    "print(\"\\nPer-layer MACs (batch=1):\")\n",
    "for name, out_shape, macs in rows:\n",
    "    print(f\"- {name:10s}  out={out_shape:10s}  MACs={macs:,}\")\n",
    "print(f\"\\nTOTAL MACs (batch=1):  {total_macs:,}\")\n",
    "print(f\"TOTAL FLOPs (batch=1): {total_flops:,}\")\n",
    "\n",
    "print(\"\\nNotes:\")\n",
    "print(\"- MACs/FLOPs above count Conv+Linear only.\")\n",
    "print(\"- BatchNorm/ReLU/Dropout/Pooling also cost ops but are typically reported separately.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 4) Train: dataset load time + preload time + per-epoch metrics\n",
    "# ==========================================================\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "# ---------------------------\n",
    "# Env vars consumed by model.py\n",
    "# ---------------------------\n",
    "os.environ[\"EPOCHS\"] = str(EPOCHS)\n",
    "os.environ[\"BATCH_SIZE\"] = str(BATCH_SIZE)\n",
    "os.environ[\"LR\"] = str(LR)\n",
    "os.environ[\"SEED\"] = str(SEED)\n",
    "os.environ[\"LOG_EVERY_SEC\"] = str(LOG_EVERY_SEC)\n",
    "os.environ[\"LOG_EVERY_BATCHES\"] = str(LOG_EVERY_BATCHES)\n",
    "os.environ[\"METRICS_EVERY_BATCHES\"] = str(METRICS_EVERY_BATCHES)\n",
    "os.environ[\"VAL_EVERY\"] = str(VAL_EVERY)\n",
    "\n",
    "WEIGHTS_OUT = \"cnn_weights.pkl\"\n",
    "CLASSES_OUT = \"class_names.json\"\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset scan (paths/labels) time\n",
    "# ---------------------------\n",
    "t_scan0 = time.perf_counter()\n",
    "items, class_names = load_dataset_image_label_pairs(DATA_ROOT, max_images=int(MAX_IMAGES))\n",
    "t_scan1 = time.perf_counter()\n",
    "print(f\"dataset items: {len(items)}  classes: {len(class_names)}\")\n",
    "print(f\"dataset scan time: {t_scan1 - t_scan0:.3f}s\")\n",
    "\n",
    "# ---------------------------\n",
    "# Split train/val\n",
    "# ---------------------------\n",
    "rng = random.Random(int(SEED))\n",
    "idxs = list(range(len(items)))\n",
    "rng.shuffle(idxs)\n",
    "val_n = int(round(len(idxs) * float(VAL_FRAC)))\n",
    "if float(VAL_FRAC) > 0.0 and len(idxs) >= 2:\n",
    "    val_n = max(1, val_n)\n",
    "    val_n = min(val_n, len(idxs) - 1)\n",
    "val_set = set(idxs[:val_n])\n",
    "train_items = [items[i] for i in idxs if i not in val_set]\n",
    "val_items = [items[i] for i in idxs if i in val_set]\n",
    "print(f\"split: train={len(train_items)} val={len(val_items)}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Preload images + time it\n",
    "# ---------------------------\n",
    "t0 = time.perf_counter()\n",
    "preloaded = {str(p): load_image_rgb_u8_hwc_32x32(p) for p, _ in items}\n",
    "t1 = time.perf_counter()\n",
    "dt = t1 - t0\n",
    "rate = (len(items) / dt) if dt > 0 else 0.0\n",
    "print(f\"preloaded {len(items)} images in {dt:.3f}s  ({rate:.1f} images/sec)\")\n",
    "\n",
    "def load_arr(path):\n",
    "    return preloaded[str(path)]\n",
    "\n",
    "# ---------------------------\n",
    "# Train (collect per-epoch history for plots)\n",
    "# ---------------------------\n",
    "m = cpp_train.CNN(num_classes=len(class_names))\n",
    "history = cpp_train.train(\n",
    "    m,\n",
    "    train_items,\n",
    "    val_items,\n",
    "    batch_size=int(BATCH_SIZE),\n",
    "    epochs=int(EPOCHS),\n",
    "    lr=float(LR),\n",
    "    seed=int(SEED),\n",
    "    load_arr=load_arr,\n",
    "    return_history=True,\n",
    " )\n",
    "\n",
    "# ---------------------------\n",
    "# Save artifacts\n",
    "# ---------------------------\n",
    "cpp_train.save_weights(m, WEIGHTS_OUT)\n",
    "cpp_train.save_class_names(class_names, CLASSES_OUT)\n",
    "print(\"saved weights:\", WEIGHTS_OUT)\n",
    "print(\"saved class names:\", CLASSES_OUT)\n",
    "\n",
    "# Quick summary key indicators\n",
    "if history:\n",
    "    best = max((h for h in history if h.get(\"val_acc\") is not None), key=lambda x: x[\"val_acc\"], default=None)\n",
    "    if best is not None:\n",
    "        print(f\"best val_acc={best['val_acc']:.4f} at epoch {best['epoch']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# 5) Plots: loss/accuracy vs epoch (train + val)\n",
    "# ==========================================================\n",
    "import math\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception as e:\n",
    "    raise ImportError(\"matplotlib is required for plots. Install it (e.g. pip install matplotlib) and re-run.\") from e\n",
    "\n",
    "if not history:\n",
    "    raise RuntimeError(\"No training history found. Run the training cell above first.\")\n",
    "\n",
    "epochs = [h[\"epoch\"] for h in history]\n",
    "train_loss = [h[\"train_loss\"] for h in history]\n",
    "train_acc = [h[\"train_acc\"] for h in history]\n",
    "val_loss = [h[\"val_loss\"] if h.get(\"val_loss\") is not None else math.nan for h in history]\n",
    "val_acc = [h[\"val_acc\"] if h.get(\"val_acc\") is not None else math.nan for h in history]\n",
    "secs = [h.get(\"seconds\", math.nan) for h in history]\n",
    "throughput = [ (h.get(\"train_images\", 0) / h[\"seconds\"]) if h.get(\"seconds\") else math.nan for h in history ]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax[0].plot(epochs, train_loss, label=\"train_loss\")\n",
    "ax[0].plot(epochs, val_loss, label=\"val_loss\")\n",
    "ax[0].set_xlabel(\"epoch\")\n",
    "ax[0].set_ylabel(\"loss\")\n",
    "ax[0].set_title(\"Loss\")\n",
    "ax[0].grid(True, alpha=0.3)\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(epochs, train_acc, label=\"train_acc\")\n",
    "ax[1].plot(epochs, val_acc, label=\"val_acc\")\n",
    "ax[1].set_xlabel(\"epoch\")\n",
    "ax[1].set_ylabel(\"accuracy\")\n",
    "ax[1].set_title(\"Accuracy\")\n",
    "ax[1].grid(True, alpha=0.3)\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Per-epoch timing / throughput:\")\n",
    "for e, s, th in zip(epochs, secs, throughput):\n",
    "    print(f\"epoch {e:3d}  seconds={s:8.3f}  train_img/s={th:8.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b074b8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning cycle: load saved weights + tune on a small subset with augmentation\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Load full dataset (or capped)\n",
    "items, class_names = load_dataset_image_label_pairs(DATA_ROOT, max_images=int(MAX_IMAGES))\n",
    "print(f\"tuning source size: {len(items)} (MAX_IMAGES={MAX_IMAGES})\")\n",
    "\n",
    "# Pick a subset to tune on\n",
    "TUNE_EPOCHS = 5\n",
    "TUNE_BATCH_SIZE = int(BATCH_SIZE)\n",
    "TUNE_LR = float(LR) * 0.5\n",
    "TUNE_VAL_FRAC = 0.2\n",
    "TUNE_IMAGES = 10000\n",
    "\n",
    "rng = random.Random(123)\n",
    "idxs = list(range(len(items)))\n",
    "rng.shuffle(idxs)\n",
    "if int(TUNE_IMAGES) > 0:\n",
    "    idxs = idxs[: min(int(TUNE_IMAGES), len(idxs))]\n",
    "subset = [items[i] for i in idxs]\n",
    "print(f\"tuning subset size: {len(subset)} (TUNE_IMAGES={TUNE_IMAGES})\")\n",
    "\n",
    "# Preload subset (timed)\n",
    "t0 = time.perf_counter()\n",
    "preloaded = {str(p): load_image_rgb_u8_hwc_32x32(p) for p, _ in subset}\n",
    "t1 = time.perf_counter()\n",
    "print(f\"preloaded tuning subset in {t1 - t0:.3f}s\")\n",
    "\n",
    "def load_arr(path):\n",
    "    return preloaded[str(path)]\n",
    "\n",
    "# Recreate model + load saved weights\n",
    "m = cpp_train.CNN(num_classes=len(class_names))\n",
    "WEIGHTS_PATH = \"cnn_weights.pkl\"\n",
    "if not os.path.exists(WEIGHTS_PATH):\n",
    "    raise FileNotFoundError(f\"weights not found: {WEIGHTS_PATH}. Run Cell 2 first.\")\n",
    "cpp_train.load_weights(m, WEIGHTS_PATH)\n",
    "print(\"loaded weights:\", WEIGHTS_PATH)\n",
    "\n",
    "# Split subset into tune-train / tune-val\n",
    "val_n = int(round(len(subset) * float(TUNE_VAL_FRAC)))\n",
    "val_n = max(1, val_n) if len(subset) >= 2 else 0\n",
    "tune_val = subset[:val_n]\n",
    "tune_train = subset[val_n:]\n",
    "print(f\"tune split: train={len(tune_train)} val={len(tune_val)}\")\n",
    "\n",
    "# Make it chatty during tuning\n",
    "os.environ[\"LOG_EVERY_SEC\"] = \"0\"\n",
    "os.environ[\"LOG_EVERY_BATCHES\"] = \"1\"\n",
    "os.environ[\"METRICS_EVERY_BATCHES\"] = \"1\"\n",
    "os.environ[\"VAL_EVERY\"] = \"1\"\n",
    "\n",
    "# Enable augmentation during tuning (read by model.py)\n",
    "os.environ[\"AUGMENT\"] = \"1\"\n",
    "os.environ[\"AUG_FLIP_PROB\"] = \"0.5\"\n",
    "os.environ[\"AUG_TRANSLATE\"] = \"0.1\"\n",
    "os.environ[\"AUG_ROTATE_DEG\"] = \"5\"\n",
    "\n",
    "cpp_train.train(\n",
    "    m,\n",
    "    tune_train,\n",
    "    tune_val,\n",
    "    batch_size=int(TUNE_BATCH_SIZE),\n",
    "    epochs=int(TUNE_EPOCHS),\n",
    "    lr=float(TUNE_LR),\n",
    "    seed=123,\n",
    "    load_arr=load_arr,\n",
    " )\n",
    "\n",
    "# Save tuned weights separately\n",
    "TUNED_OUT = \"cnn_weights_tuned_1.pkl\"\n",
    "cpp_train.save_weights(m, TUNED_OUT)\n",
    "print(\"saved tuned weights:\", TUNED_OUT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c1f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tuned weights on test images\n",
    "import os\n",
    "import time\n",
    "\n",
    "TEST_ROOT = \"testing\"\n",
    "TUNED_WEIGHTS = \"cnn_weights_tuned_1.pkl\"\n",
    "BATCH_SIZE_EVAL = int(BATCH_SIZE)\n",
    "\n",
    "if not os.path.exists(TUNED_WEIGHTS):\n",
    "    raise FileNotFoundError(f\"tuned weights not found: {TUNED_WEIGHTS}\")\n",
    "\n",
    "test_items, test_class_names = load_dataset_image_label_pairs(TEST_ROOT, max_images=0)\n",
    "print(f\"test dataset: n={len(test_items)} classes={len(test_class_names)}\")\n",
    "\n",
    "# Preload test set (timed)\n",
    "t0 = time.perf_counter()\n",
    "preloaded = {str(p): load_image_rgb_u8_hwc_32x32(p) for p, _ in test_items}\n",
    "t1 = time.perf_counter()\n",
    "print(f\"preloaded test set in {t1 - t0:.3f}s\")\n",
    "\n",
    "def load_arr(path):\n",
    "    return preloaded[str(path)]\n",
    "\n",
    "m_test = cpp_train.CNN(num_classes=len(test_class_names))\n",
    "cpp_train.load_weights(m_test, TUNED_WEIGHTS)\n",
    "print(\"loaded tuned weights:\", TUNED_WEIGHTS)\n",
    "\n",
    "test_loss, test_acc = cpp_train._eval_epoch(\n",
    "    m_test, test_items, batch_size=max(1, int(BATCH_SIZE_EVAL)), load_arr=load_arr\n",
    ")\n",
    "\n",
    "print(f\"TEST  loss={test_loss:.6f}  acc={test_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
